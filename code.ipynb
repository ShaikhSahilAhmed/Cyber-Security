{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahil/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/home/sahil/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/home/sahil/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "\n",
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#importing the dataset\n",
    "dataset = pd.read_csv('kddcup.data_10_percent_corrected')\n",
    "\n",
    "#change Multi-class to binary-class\n",
    "dataset['normal.'] = dataset['normal.'].replace(['back.', 'buffer_overflow.', 'ftp_write.', 'guess_passwd.', 'imap.', 'ipsweep.', 'land.', 'loadmodule.', 'multihop.', 'neptune.', 'nmap.', 'perl.', 'phf.', 'pod.', 'portsweep.', 'rootkit.', 'satan.', 'smurf.', 'spy.', 'teardrop.', 'warezclient.', 'warezmaster.'], 'attack')\n",
    "\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 41].values\n",
    "\n",
    "#encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_x_1 = LabelEncoder()\n",
    "labelencoder_x_2 = LabelEncoder()\n",
    "labelencoder_x_3 = LabelEncoder()\n",
    "x[:, 1] = labelencoder_x_1.fit_transform(x[:, 1])\n",
    "x[:, 2] = labelencoder_x_2.fit_transform(x[:, 2])\n",
    "x[:, 3] = labelencoder_x_3.fit_transform(x[:, 3])\n",
    "onehotencoder_1 = OneHotEncoder(categorical_features = [1])\n",
    "x = onehotencoder_1.fit_transform(x).toarray()\n",
    "onehotencoder_2 = OneHotEncoder(categorical_features = [4])\n",
    "x = onehotencoder_2.fit_transform(x).toarray()\n",
    "onehotencoder_3 = OneHotEncoder(categorical_features = [70])\n",
    "x = onehotencoder_3.fit_transform(x).toarray()\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into the training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 345814 samples, validate on 148206 samples\n",
      "Epoch 1/10\n",
      "345814/345814 [==============================] - 44s 128us/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.0074 - val_accuracy: 0.9991\n",
      "Epoch 2/10\n",
      "345814/345814 [==============================] - 45s 129us/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "345814/345814 [==============================] - 44s 127us/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "345814/345814 [==============================] - 47s 135us/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "345814/345814 [==============================] - 47s 136us/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "345814/345814 [==============================] - 46s 133us/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
      "Epoch 7/10\n",
      "345814/345814 [==============================] - 43s 124us/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "345814/345814 [==============================] - 44s 127us/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "345814/345814 [==============================] - 44s 126us/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "345814/345814 [==============================] - 44s 127us/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0094 - val_accuracy: 0.9994\n",
      "the Accuracy is: 0.9993792424058405\n",
      "Recall is : 0.9979252406380735\n",
      "False Positive rate: 0.0002609317789655318\n",
      "Precision is: 0.9989445371284601\n",
      "F-measure is: 0.9984346287347717\n",
      "Entropy is: 0.0010549056745352183\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential                #DNN with one layer\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=118,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=64, epochs=10, verbose=1)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#the performance of the classification model\n",
    "print(\"the Accuracy is: \"+ str((cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])))\n",
    "recall = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "print(\"Recall is : \"+ str(recall))\n",
    "print(\"False Positive rate: \"+ str(cm[1,0]/(cm[0,0]+cm[1,0])))\n",
    "precision = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Precision is: \"+ str(precision))\n",
    "print(\"F-measure is: \"+ str(2*((precision*recall)/(precision+recall))))\n",
    "from math import log\n",
    "print(\"Entropy is: \"+ str(-precision*log(precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 345814 samples, validate on 148206 samples\n",
      "Epoch 1/10\n",
      "345814/345814 [==============================] - 165s 476us/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9989\n",
      "Epoch 2/10\n",
      "345814/345814 [==============================] - 143s 413us/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0043 - val_accuracy: 0.9989\n",
      "Epoch 3/10\n",
      "345814/345814 [==============================] - 147s 425us/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
      "Epoch 4/10\n",
      "345814/345814 [==============================] - 169s 488us/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
      "Epoch 5/10\n",
      "345814/345814 [==============================] - 158s 458us/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0046 - val_accuracy: 0.9981\n",
      "Epoch 6/10\n",
      "345814/345814 [==============================] - 136s 394us/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9975\n",
      "Epoch 7/10\n",
      "345814/345814 [==============================] - 140s 404us/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0108 - val_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "345814/345814 [==============================] - 156s 450us/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
      "Epoch 9/10\n",
      "345814/345814 [==============================] - 167s 484us/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0511 - val_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "345814/345814 [==============================] - 166s 481us/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9991\n",
      "the Accuracy is: 0.9990823583390686\n",
      "Recall is : 0.9986355108306327\n",
      "False Positive rate: 0.0008074622973984574\n",
      "Precision is: 0.9967314698171665\n",
      "F-measure is: 0.997682581876427\n",
      "Entropy is: 0.003263182708749939\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential             #DNN with 5 layer\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=118,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(128,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(64,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=64, epochs=10, verbose=1)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#the performance of the classification model\n",
    "print(\"the Accuracy is: \"+ str((cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])))\n",
    "recall = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "print(\"Recall is : \"+ str(recall))\n",
    "print(\"False Positive rate: \"+ str(cm[1,0]/(cm[0,0]+cm[1,0])))\n",
    "precision = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Precision is: \"+ str(precision))\n",
    "print(\"F-measure is: \"+ str(2*((precision*recall)/(precision+recall))))\n",
    "from math import log\n",
    "print(\"Entropy is: \"+ str(-precision*log(precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "345814/345814 [==============================] - 88s 255us/step - loss: 0.0067 - accuracy: 0.9983\n",
      "Epoch 2/10\n",
      "345814/345814 [==============================] - 84s 244us/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "345814/345814 [==============================] - 84s 243us/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "345814/345814 [==============================] - 84s 243us/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 5/10\n",
      "345814/345814 [==============================] - 85s 245us/step - loss: 0.0038 - accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "345814/345814 [==============================] - 84s 244us/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "345814/345814 [==============================] - 84s 243us/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 8/10\n",
      "345814/345814 [==============================] - 85s 245us/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "345814/345814 [==============================] - 84s 244us/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "345814/345814 [==============================] - 84s 243us/step - loss: 0.0037 - accuracy: 0.9993\n",
      "the Accuracy is: 0.9993117687543015\n",
      "Recall is : 0.9987730479533758\n",
      "False Positive rate: 0.0005552517561940016\n",
      "Precision is: 0.9977528854993021\n",
      "F-measure is: 0.9982627060907481\n",
      "Entropy is: 0.0022445878456376794\n"
     ]
    }
   ],
   "source": [
    "#ANN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 60, init = 'uniform', activation = 'relu', input_dim = 118))\n",
    "\n",
    "#Adding a second hidden layer\n",
    "classifier.add(Dense(output_dim = 60, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "#Adding a third hidden layer\n",
    "classifier.add(Dense(output_dim = 60, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(x_train, y_train, batch_size = 10, nb_epoch = 10)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#the performance of the classification model\n",
    "print(\"the Accuracy is: \"+ str((cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])))\n",
    "recall = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "print(\"Recall is : \"+ str(recall))\n",
    "print(\"False Positive rate: \"+ str(cm[1,0]/(cm[0,0]+cm[1,0])))\n",
    "precision = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Precision is: \"+ str(precision))\n",
    "print(\"F-measure is: \"+ str(2*((precision*recall)/(precision+recall))))\n",
    "from math import log\n",
    "print(\"Entropy is: \"+ str(-precision*log(precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 0.9480385409497591\n",
      "Recall is : 0.7926796326310103\n",
      "False Positive rate: 0.00023384239022898566\n",
      "Precision is: 0.9991147730754826\n",
      "F-measure is: 0.8840053621725836\n",
      "Entropy is: 0.0008848349954977019\n"
     ]
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "\n",
    "#the performance of the classification model\n",
    "print(\"The Accuracy is: \"+ str((cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])))\n",
    "recall = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "print(\"Recall is : \"+ str(recall))\n",
    "print(\"False Positive rate: \"+ str(cm[1,0]/(cm[0,0]+cm[1,0])))\n",
    "precision = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Precision is: \"+ str(precision))\n",
    "print(\"F-measure is: \"+ str(2*((precision*recall)/(precision+recall))))\n",
    "from math import log\n",
    "print(\"Entropy is: \"+ str(-precision*log(precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 0.9986235375086029\n",
      "Recall is : 0.9960205435189279\n",
      "False Positive rate: 0.0007322924119355246\n",
      "Precision is: 0.9970378945218072\n",
      "F-measure is: 0.9965289593684066\n",
      "Entropy is: 0.00295771410571443\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "\n",
    "#the performance of the classification model\n",
    "print(\"The Accuracy is: \"+ str((cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])))\n",
    "recall = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "print(\"Recall is : \"+ str(recall))\n",
    "print(\"False Positive rate: \"+ str(cm[1,0]/(cm[0,0]+cm[1,0])))\n",
    "precision = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Precision is: \"+ str(precision))\n",
    "print(\"F-measure is: \"+ str(2*((precision*recall)/(precision+recall))))\n",
    "from math import log\n",
    "print(\"Entropy is: \"+ str(-precision*log(precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 0.9997503474893055\n",
      "Recall is : 0.9994211386543176\n",
      "False Positive rate: 0.00016829633618876117\n",
      "Precision is: 0.9993190562119098\n",
      "F-measure is: 0.9993700948262653\n",
      "Entropy is: 0.0006807118932272154\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "\n",
    "#the performance of the classification model\n",
    "print(\"The Accuracy is: \"+ str((cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])))\n",
    "recall = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "print(\"Recall is : \"+ str(recall))\n",
    "print(\"False Positive rate: \"+ str(cm[1,0]/(cm[0,0]+cm[1,0])))\n",
    "precision = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Precision is: \"+ str(precision))\n",
    "print(\"F-measure is: \"+ str(2*((precision*recall)/(precision+recall))))\n",
    "from math import log\n",
    "print(\"Entropy is: \"+ str(-precision*log(precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 0.9998515579666141\n",
      "Recall is : 0.9993874425727411\n",
      "False Positive rate: 3.3664082948300384e-05\n",
      "Precision is: 0.999863811242382\n",
      "F-measure is: 0.9996255701545373\n",
      "Entropy is: 0.00013617948350813525\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "\n",
    "#the performance of the classification model\n",
    "print(\"The Accuracy is: \"+ str((cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])))\n",
    "recall = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "print(\"Recall is : \"+ str(recall))\n",
    "print(\"False Positive rate: \"+ str(cm[1,0]/(cm[0,0]+cm[1,0])))\n",
    "precision = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Precision is: \"+ str(precision))\n",
    "print(\"F-measure is: \"+ str(2*((precision*recall)/(precision+recall))))\n",
    "from math import log\n",
    "print(\"Entropy is: \"+ str(-precision*log(precision)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
